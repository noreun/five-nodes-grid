{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import makegridslibrary as me\n",
    "from pypci import pci\n",
    "\n",
    "import pyphi\n",
    "\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import solarized\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "# solarized.light()\n",
    "# solarized.dark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "## First load \\Phi results from Pyphi\n",
    "##########################################################################################################################\n",
    "\n",
    "# Import probability of occuppying each state and use it as weight for:\n",
    "\n",
    "# * \\Phi\n",
    "# * \\sum \\phi\n",
    "# * \\sum \\Phi * \\phi\n",
    "\n",
    "def read_prob_state(file_name):\n",
    "    ps = np.transpose(scio.loadmat(file_name)['all_states'], (0, 2, 3, 1))\n",
    "    nps = ps.shape\n",
    "    N = 0 # only the 5 nodes\n",
    "    pss = np.zeros((nps[1], 32))\n",
    "    for itemp in range(nps[1]):\n",
    "        pss[itemp, :] = np.mean(\n",
    "            np.array([ np.histogram(ps[N, itemp, run, :], range(0,33), density=True)[0] for run in range(nps[2]) ]),\n",
    "            axis = 0\n",
    "        )\n",
    "    return pss\n",
    "\n",
    "# grid_states = '/data/nsdm/pyphi/dynamics/all_states_5_nodes_non_cm_grid_fpp_T_0.0_1.4_15.mat'\n",
    "# rand_states = '/data/nsdm/pyphi/dynamics/all_states_5_nodes_non_cm_rand_fpp_T_0.0_1.4_15.mat'\n",
    "\n",
    "grid_states = '/data/nsdm/pyphi/dynamics/all_states_5_nodes_non_cm_grid_fpp_T_0.0_2.8_12.mat'\n",
    "rand_states = '/data/nsdm/pyphi/dynamics/all_states_5_nodes_non_cm_rand_fpp_T_0.0_2.8_12.mat'\n",
    "\n",
    "# grid_states = '/data/nsdm/pyphi/dynamics/all_states_5_nodes_non_cm_grid_fpp_T_0.5_1.0_2.mat'\n",
    "# rand_states = '/data/nsdm/pyphi/dynamics/all_states_5_nodes_non_cm_rand_fpp_T_0.5_1.0_2.mat'\n",
    "\n",
    "grid_prob_state = read_prob_state(grid_states)\n",
    "rand_prob_state = read_prob_state(rand_states)\n",
    "\n",
    "# Load results from matching_LB.py\n",
    "\n",
    "results_filename = '/data/nsdm/pyphi/fivenodes_noinput_gridVSrandom_ENTROPY_WEDGE_DIFFSUM_T_0_3_D_2_MAIN_SAVED_new.pickle'\n",
    "#results_filename = '/data/nsdm/pyphi/fivenodes_noinput_gridVSrandom_ENTROPY_WEDGE_DIFFSUM_T_0_3_D_2_MAIN_SAVED.pickle'\n",
    "trange = [0, 2.75]\n",
    "\n",
    "# results_filename = '/data/nsdm/pyphi/fivenodes_barVSshuffled_gridVSrandom_ENTROPY_WEDGE_DIFFSUM_T_0_1_D_2_MAIN_SAVED.pickle'\n",
    "# trange = [0, 1.4]\n",
    "\n",
    "# results_filename = '/data/nsdm/pyphi/fivenodes_noinput_gridVSrandom_ENTROPY_WEDGE_DIFFSUM_T_0.5_1.0_D_2_L2_MAIN_SAVED.pickle'\n",
    "# trange = [.5, 1.]\n",
    "\n",
    "with open(results_filename, 'rb') as f: \n",
    "    results = pickle.load(f)\n",
    "results = results[0]\n",
    "\n",
    "ntemp = len(results['Grid'])\n",
    "temperatures = np.linspace(trange[0], trange[1], ntemp)\n",
    "\n",
    "do_plot = False\n",
    "# do_plot = True\n",
    "\n",
    "# ignore_homo = True\n",
    "ignore_homo = False\n",
    "\n",
    "# weight_state = True\n",
    "weight_state = False\n",
    "\n",
    "def operation(concepts, big_phi, operation_type = 'concepts * big_phi'):\n",
    "    values = eval(operation_type)\n",
    "    return (np.sum(values), np.std(values))\n",
    "\n",
    "# network_labels = ['Random']\n",
    "# network_labels = ['Grid']\n",
    "network_labels = ['Grid', 'Random']\n",
    "operation_types = ['concepts * big_phi', 'big_phi', 'concepts']\n",
    "\n",
    "all_results =  {x: {y: np.zeros(ntemp) for y in operation_types} for x in network_labels}\n",
    "all_results_std = {x: {y: np.zeros(ntemp) for y in operation_types} for x in network_labels}\n",
    "\n",
    "for network_label in network_labels:\n",
    "    \n",
    "    if do_plot:\n",
    "#         fig, axis = plt.subplots(int(len(temperatures)/2)+1, 2)\n",
    "        fig, axis = plt.subplots(len(temperatures), 2)\n",
    "        fig.set_size_inches(12,12)\n",
    "        \n",
    "    for operation_type in operation_types:\n",
    "        \n",
    "        for (itemp, temp) in enumerate(sorted(results[network_label])):\n",
    "            \n",
    "            print('%s, temp = %2.2f, operation: %s' % (network_label, temp, operation_type))\n",
    "            \n",
    "            this_result = results[network_label][temp]\n",
    "            number_result = np.zeros(len(this_result))\n",
    "            number_result_dict = {}\n",
    "            \n",
    "            phi = np.zeros(len(this_result))\n",
    "            phi_std = np.zeros(len(this_result))\n",
    "            for (istate, this_state) in enumerate(this_result):\n",
    "\n",
    "                state_ok = len(this_result[this_state][1]) > 0\n",
    "\n",
    "                if ignore_homo:\n",
    "                    state_ok = state_ok & (sum(this_state[:5]) > 0 and sum(this_state[:5]) < len(this_state[:5]))\n",
    "\n",
    "                if state_ok:\n",
    "                    number_result[istate] = len(this_result[this_state][1])\n",
    "                    number_result_dict[this_state] = len(this_result[this_state][1])\n",
    "\n",
    "                    (stat_1, stat_2) = operation(np.array(this_result[this_state][1]), this_result[this_state][0], operation_type)\n",
    "                    (phi[istate], phi_std[istate]) = (stat_1, stat_2)\n",
    "\n",
    "\n",
    "            if do_plot: # and itemp%2 == 0:\n",
    "    #             idx = int(itemp/2)\n",
    "                idx = itemp\n",
    "                axis[idx, 0].hist(phi)\n",
    "                axis[idx, 0].axvline(x=np.mean(phi), color='r')\n",
    "                axis[idx, 0].set_title('mean: %2.5f' % np.mean(phi))\n",
    "                axis[idx, 0].set_ylabel('T: %2.2f' % temp)\n",
    "\n",
    "            if weight_state:\n",
    "                if network_label == 'Random':\n",
    "                    phi = phi * rand_prob_state[itemp,:]\n",
    "                    phi_std = phi_std * rand_prob_state[itemp,:]\n",
    "                else:\n",
    "                    phi = phi * grid_prob_state[itemp,:]\n",
    "                    phi_std = phi_std * grid_prob_state[itemp,:]\n",
    "                \n",
    "            all_results[network_label][operation_type][itemp] = np.mean(phi)\n",
    "            all_results_std[network_label][operation_type][itemp] = np.sqrt(np.mean(phi_std**2))\n",
    "\n",
    "    if do_plot:\n",
    "        plt.tight_layout()\n",
    "#         fig.suptitle(network_label + ' : ' + operation_type)\n",
    "        fig.suptitle(network_label)\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "    \n",
    "if do_plot:\n",
    "    plt.show()\n",
    "    \n",
    "# print(all_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_filename, 'rb') as f: \n",
    "    results = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import solarized\n",
    "\n",
    "# t0 = 2\n",
    "t0 = 0\n",
    "\n",
    "markers = {'Grid': 'o', 'Random': 'P'}\n",
    "b = solarized.COLOR[\"blue\"]\n",
    "r = solarized.COLOR[\"red\"]\n",
    "m = solarized.COLOR[\"magenta\"]\n",
    "\n",
    "network = 'Grid'\n",
    "plt.figure(figsize = (17,6))\n",
    "for (iop, operation) in enumerate(sorted(all_results[network])):\n",
    "\n",
    "    plt.subplot(1,3,iop+1)\n",
    "    plt.errorbar(temperatures[t0:], all_results[network][operation][t0:], yerr=all_results_std[network][operation][t0:], fmt=markers[network], color=b)\n",
    "    plt.title(network + ' : ' + operation)\n",
    "    plt.ylabel('Phi')\n",
    "    plt.xlabel('Noise')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "network = 'Random'\n",
    "plt.figure(figsize = (17,6))\n",
    "for (iop, operation) in enumerate(sorted(all_results[network])):\n",
    "\n",
    "    plt.subplot(1,3,iop+1)\n",
    "    plt.errorbar(temperatures[t0:], all_results[network][operation][t0:], yerr=all_results_std[network][operation][t0:], fmt=markers[network], color=b)\n",
    "    plt.title(network + ' : ' + operation)\n",
    "    plt.ylabel('Phi')\n",
    "    plt.xlabel('Noise')\n",
    "plt.show()    \n",
    "\n",
    "\n",
    "plt.figure(figsize = (17,6))\n",
    "\n",
    "for (iop, operation) in enumerate(sorted(all_results[network])):\n",
    "\n",
    "    plt.subplot(1,3,iop+1)\n",
    "    y = all_results['Grid'][operation][t0:] - all_results['Random'][operation][t0:]\n",
    "    yerr = np.sqrt(np.sum(all_results_std['Grid'][operation][t0:]**2 + all_results_std['Random'][operation][t0:]**2))\n",
    "    plt.errorbar(temperatures[t0:], y, yerr=yerr, fmt='s', color=m)\n",
    "    plt.title(network + ' : ' + operation)\n",
    "    plt.ylabel('Phi')\n",
    "    plt.xlabel('Noise')\n",
    "        \n",
    "plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "## Specify mutual information results that should be used\n",
    "##########################################################################################################################\n",
    "\n",
    "from matplotlib.pyplot import savefig\n",
    "from subprocess import call\n",
    "\n",
    "fig_out_dir = '/home/leonardo/projects/nsdm-pyphi/docs/auto'\n",
    "\n",
    "mi_input_dir = '/data/nsdm/pyphi/dynamics/mi'\n",
    "\n",
    "mi_input_files = ['measure_d1_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "# mi_input_files = ['measure_dte_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_dte_v2_grid_rand_non_test_T_0.5_1.0.pickle']\n",
    "\n",
    "b = solarized.COLOR[\"blue\"]\n",
    "r = solarized.COLOR[\"red\"]\n",
    "m = solarized.COLOR[\"magenta\"]\n",
    "\n",
    "markers = {'Grid': 'o', 'Random': 'x'}\n",
    "fcolor = {'Grid': m, 'Random': 'none'}\n",
    "\n",
    "t0 = 2\n",
    "# t0 = 0\n",
    "\n",
    "imn = 1\n",
    "\n",
    "ts = temperatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "## Show MI information per temperature\n",
    "##########################################################################################################################\n",
    "\n",
    "do_simple_mi_plot = False\n",
    "# do_simple_mi_plot = True\n",
    "\n",
    "do_plot_mi_per_temp = False\n",
    "# do_plot_mi_per_temp = True\n",
    "\n",
    "do_plot_diff_grid_rand = False\n",
    "# do_plot_diff_grid_rand = True\n",
    "\n",
    "\n",
    "def plot_mi_per_temp(net):\n",
    "    \n",
    "    imn = 1\n",
    "    \n",
    "    nt = len(net[2])\n",
    "    nruns = len(net[2][0])\n",
    "    n_mecs = net[2][0][0][imn].shape[0]\n",
    "    # plt.plot([(n+1) * net[2][t][r][2][0] - net[2][t][r][2][n] for n in range(n_mecs)])\n",
    "    t_hs = []\n",
    "    tcolors = cm.Paired([x for x in np.linspace(0., 1., nt)])\n",
    "    for (t, color) in zip(range(nt), tcolors):\n",
    "        runs = np.mean(np.array([net[2][t][r][imn] for r in range(nruns)]), axis=0)\n",
    "        runs_std = np.std(np.array([net[2][t][r][imn] for r in range(nruns)]), axis=0)\n",
    "        t_h = plt.errorbar(range(1,n_mecs+1), runs, yerr=runs_std, color=color)\n",
    "        ext_m0 = range(1, n_mecs+1)\n",
    "        plt.plot(ext_m0, [ext * runs[0] for ext in ext_m0], color=color, ls='--')\n",
    "        t_hs.append(t_h)\n",
    "    plt.legend(t_hs, [str(t) for t in range(nt)])\n",
    "\n",
    "\n",
    "\n",
    "all_phi = {'non': (all_results, all_results_std)}\n",
    "    \n",
    "if do_plot_diff_grid_rand:    \n",
    "    \n",
    "    fig_phi_root = 'diff_rand_grid'\n",
    "    fig_files_phi = []\n",
    "    \n",
    "    for (iop, operation) in enumerate(['big_phi', 'concepts']):    \n",
    "        \n",
    "        # Difference in big phi and sunm opf concepts\n",
    "        plt.figure(figsize = (17,6))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        netgrid = all_phi['non'][0]['Grid'][operation]\n",
    "        netrand = all_phi['non'][0]['Random'][operation]\n",
    "        plt.errorbar(ts[t0:], netgrid[t0:]-netrand[t0:], \n",
    "                     fmt='s', color=m, markersize=10)\n",
    "        plt.ylabel('Grid - Rand')\n",
    "        plt.xlabel('Temperature')\n",
    "        plt.title('Measure: %s, Tau: %d' % (operation, tau))\n",
    "        \n",
    "        fig_name = '%s/%s_%s.png' % (fig_out_dir, fig_phi_root, operation)\n",
    "        fig_files_phi.append(fig_name)\n",
    "        savefig(fig_name)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    if len(fig_files_corr):\n",
    "        call([\"convert\"] + fig_files_phi + ['-append', '%s/%s.png' % (fig_out_dir, fig_phi_root)])\n",
    "\n",
    "for mi_input_file in mi_input_files:\n",
    "\n",
    "    display(HTML(\"<center><h1 style='font-size: %dpx;height: 100;'>%s</h1></center>\" % (20, mi_input_file)))\n",
    "        \n",
    "    with open('%s/%s' % (mi_input_dir, mi_input_file), 'rb') as f:\n",
    "        mis = pickle.load(f)\n",
    "\n",
    "    fig_files = []\n",
    "    fig_out_root = 'corr_phi_mi_no_input'\n",
    "    \n",
    "    fig_files_corr = []\n",
    "    fig_out_corr_root = 'corr_phi_mi_no_input_diff_grid_rand'\n",
    "    \n",
    "    for tau in mis:\n",
    "\n",
    "        networks_d = {'Grid': {'non': mis[tau]['non_grid']}, 'Random': {'non': mis[tau]['non_rand']}}\n",
    "\n",
    "#         networks_d = {'Grid': {'non': mis[tau]['non_grid']}}\n",
    "#         networks_d = {'Random': {'non': mis[tau]['non_rand']}}\n",
    "        \n",
    "        \n",
    "        # mutual information for each network\n",
    "        if do_plot_mi_per_temp:\n",
    "            for (inet, network_label) in enumerate(sorted(networks_d)):\n",
    "\n",
    "                plt.figure(figsize = (17,6))\n",
    "\n",
    "                network = networks_d[network_label]\n",
    "\n",
    "                for (ilabel, label) in enumerate(['non']):\n",
    "                    ax = plt.subplot(1,2,ilabel+1)\n",
    "                    plot_mi_per_temp(network[label])\n",
    "                    ax.set_title('net: %s, input: %s, tau: %d' % (network_label, label, tau))\n",
    "                plt.show()\n",
    "\n",
    "                \n",
    "        # Degeneracy-like measure for each network\n",
    "        if do_simple_mi_plot:\n",
    "            plt.figure(figsize = (17,6))\n",
    "            for (inet, network_label) in enumerate(sorted(networks_d)):\n",
    "\n",
    "                network = networks_d[network_label]\n",
    "\n",
    "                plt.subplot(1,2,inet+1)\n",
    "                plt.errorbar(ts[t0:], network['non'][0][t0:], yerr=network['non'][1][t0:], \n",
    "                             fmt=markers[network_label], color=b, markersize=10)\n",
    "                plt.title(network_label + ' tau = ' + str(tau))\n",
    "                plt.ylabel(measure)\n",
    "                plt.xlabel('Temperature')\n",
    "\n",
    "            plt.show()    \n",
    "        \n",
    "\n",
    "        if do_plot_diff_grid_rand:\n",
    "            # Difference in degeneracy-like measure\n",
    "            plt.figure(figsize = (17,6))\n",
    "\n",
    "            plt.subplot(1,3,1)\n",
    "            netgrid = networks_d['Grid']\n",
    "            netrand = networks_d['Random']\n",
    "            plt.errorbar(ts[t0:], netgrid['non'][0][t0:]-netrand['non'][0][t0:], \n",
    "                         fmt='s', color=m, markersize=10)\n",
    "            plt.ylabel('Grid - Rand')\n",
    "            plt.xlabel('Temperature')\n",
    "            plt.title('Measure: %s, Tau: %d' % (measure, tau))\n",
    "\n",
    "            for (iop, operation) in enumerate(['big_phi', 'concepts']):    \n",
    "\n",
    "                netgrid_phi = all_phi['non'][0]['Grid'][operation]\n",
    "                netrand_phi = all_phi['non'][0]['Random'][operation]\n",
    "                \n",
    "                ax = plt.subplot(1,3,iop+2)\n",
    "\n",
    "#                 scatter_kwargs = {\"zorder\":100}\n",
    "#                 error_kwargs = {\"lw\":.5, \"zorder\":0}\n",
    "\n",
    "                X = netgrid_phi[t0:]-netrand_phi[t0:]\n",
    "#                 Y = np.log(netgrid['non'][0][t0:])-np.log(netrand['non'][0][t0:])\n",
    "                Y = netgrid['non'][0][t0:] - netrand['non'][0][t0:]\n",
    "                C = cm.jet(np.linspace(0, 1, len(temperatures[t0:])))\n",
    "\n",
    "                im = plt.scatter(X,Y,c=C, marker='s',s=80, **scatter_kwargs)\n",
    "#                 plt.errorbar(X, Y, fmt=markers[network], **error_kwargs)\n",
    "\n",
    "                plt.ylabel('log(%s)' % measure)\n",
    "                plt.xlabel(operation)\n",
    "                plt.title('Measure: %s, Tau: %d' % (operation, tau))\n",
    "\n",
    "                ax.autoscale(enable=True, axis='x', tight=True)\n",
    "#                 xlims = [a*b for (a,b) in zip([.95, 1.05], [np.min(X), np.max(X)])]\n",
    "                ax.set_xlim([-.001, .001]) \n",
    "\n",
    "#             fig_name = '%s/%s_%s_%d.png' % (fig_out_dir, fig_out_corr_root, measure, tau)\n",
    "#             fig_files_corr.append(fig_name)\n",
    "#             savefig(fig_name)\n",
    "    \n",
    "            plt.show()            \n",
    "            \n",
    "\n",
    "#     if len(fig_files):\n",
    "#         call([\"convert\"] + fig_files + ['-append', '%s/%s.png' % (fig_out_dir, fig_out_root)])\n",
    "\n",
    "#     if len(fig_files_corr):\n",
    "#         call([\"convert\"] + fig_files_corr + ['-append', '%s/%s.png' % (fig_out_dir, fig_out_corr_root)])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "## Correlate MI results with Pyphi results\n",
    "##########################################################################################################################\n",
    "\n",
    "import scipy \n",
    "\n",
    "fig_out_root = 'corr_phi_mi_no_input'\n",
    "\n",
    "t0 = 2\n",
    "# t0 = 0\n",
    "\n",
    "# mi_input_files = ['measure_d1_v2_grid_rand_non_test_T_0.0_2.8.pickle',\n",
    "#                  'measure_dte_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "\n",
    "mi_input_files = ['measure_d1_mice_grid_rand_non_test_T_0.0_2.8_new2.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_d1_mice_grid_rand_non_test_T_0.0_2.8_new.pickle',\n",
    "# 'measure_d1_cause_grid_rand_non_test_T_0.0_2.8_new.pickle',\n",
    "# 'measure_d1_effect_grid_rand_non_test_T_0.0_2.8_new.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_d1_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "# mi_input_files = ['measure_dte_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_d1_v2_grid_rand_non_test_T_0.0_2.8.pickle',\n",
    "#                  'measure_dte_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_dte_v2_grid_rand_non_test_T_0.5_1.0.pickle']\n",
    "\n",
    "markers = {'Grid': 'o-', 'Random': 'x--'}\n",
    "fcolor = {'Grid': m, 'Random': 'none'}\n",
    "\n",
    "use_average_mi = True\n",
    "# use_average_mi = False\n",
    "\n",
    "input_types = ['non']\n",
    "\n",
    "def sum_mi_over_mechanisms(all_measures):\n",
    "    \n",
    "    all_mi = all_measures[2]\n",
    "\n",
    "    ntemp = len(all_mi)\n",
    "    nruns = len(all_mi[0])\n",
    "    maxmec = len(all_mi[0][0][imn])+1\n",
    "\n",
    "#     Y_mean = [np.mean([np.sum(all_mi[t][r][imn]) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "#     Y_std = [np.std([np.sum(all_mi[t][r][imn]) for r in range(nruns)]) for t in range(ntemp)]  \n",
    "\n",
    "    Y_mean = [np.mean([np.sum(m/n for m,n in zip(all_mi[t][r][imn], range(1,maxmec))) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "    Y_std = [np.std([np.sum(m/n for m,n in zip(all_mi[t][r][imn], range(1,maxmec))) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "\n",
    "    return Y_mean, Y_std\n",
    "\n",
    "def log_sum_mi_over_mechanisms(all_measures):\n",
    "    Y_mean, Y_std = sum_mi_over_mechanisms(all_measures)\n",
    "    return np.log(Y_mean), Y_std\n",
    "\n",
    "def log_degeneracy(all_measures):\n",
    "    return np.log(np.abs(all_measures[0])), all_measures[1]\n",
    "\n",
    "def degeneracy(all_measures):\n",
    "    return all_measures[0], all_measures[1]\n",
    "\n",
    "# all_measures = [sum_mi_over_mechanisms, degeneracy]\n",
    "all_measures = [sum_mi_over_mechanisms, log_sum_mi_over_mechanisms, degeneracy, log_degeneracy]\n",
    "# all_measures = [sum_mi_over_mechanisms]\n",
    "\n",
    "all_phi = {'non': (all_results, all_results_std)}\n",
    "    \n",
    "for mi_input_file in mi_input_files:\n",
    "\n",
    "    measure_class = '_'.join(mi_input_file.split('_')[:3])\n",
    "\n",
    "    display(HTML(\"<center><h1 style='font-size: %dpx;height: 100;'>%s</h1></center>\" % (20, measure_class)))\n",
    "\n",
    "    with open('%s/%s' % (mi_input_dir, mi_input_file), 'rb') as f:\n",
    "        mis = pickle.load(f)\n",
    "\n",
    "    all_mi = {tau: {'Grid': {input_type: mis[tau][input_type + '_grid'] for input_type in input_types}, \n",
    "                    'Random': {input_type: mis[tau][input_type + '_rand'] for input_type in input_types}}\n",
    "                  for tau in mis}\n",
    "        \n",
    "    fig_files = []\n",
    "\n",
    "    for measure in all_measures:\n",
    "\n",
    "        # correlate \\Phi, \\sum \\phi and their product with MI-measures with \n",
    "        for input_type in input_types:\n",
    "\n",
    "            phi_for_input = all_phi[input_type]\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 2, sharey=True, figsize = (17,6))\n",
    "            axs[0].set_ylabel(measure.__name__)\n",
    "            axs_xlims = [[0, 0] for ax in axs]\n",
    "\n",
    "            for (inet, network) in enumerate(sorted(phi_for_input[0])):\n",
    "\n",
    "#                 cmap = matplotlib.cm.get_cmap('default', len(mis)).colors\n",
    "                for ax in axs: ax.set_prop_cycle(None)\n",
    "                \n",
    "#                 for (iop, operation) in enumerate(sorted(phi_for_input[0][network])):\n",
    "                for (iop, operation) in enumerate(['big_phi', 'concepts']):\n",
    "\n",
    "                    ax = axs[iop]\n",
    "            \n",
    "                    X = phi_for_input[0][network][operation][t0:]\n",
    "                    X_err = phi_for_input[1][network][operation][t0:]\n",
    "\n",
    "                    if np.min(X) < axs_xlims[iop][0]: axs_xlims[iop][0] = np.min(X)\n",
    "                    if np.max(X) > axs_xlims[iop][1]: axs_xlims[iop][1] = np.max(X)\n",
    "                    \n",
    "                    for (itau, tau) in enumerate(mis):\n",
    "\n",
    "                        scatter_kwargs = {\"zorder\":100}\n",
    "#                         error_kwargs = {\"lw\":.5, \"zorder\":0, \"color\":cmap[itau, :]}\n",
    "                        error_kwargs = {\"lw\":.5, \"zorder\":0}\n",
    "\n",
    "                        Y, Y_err = measure(all_mi[tau][network][input_type])\n",
    "                        Y, Y_err = Y[t0:], Y_err[t0:]\n",
    "\n",
    "                        C = cm.jet(np.linspace(0, 1, len(temperatures[t0:])))\n",
    "\n",
    "                        t_corr, p_corr = scipy.stats.pearsonr(X, Y)\n",
    "#                         t_corr, p_corr = scipy.stats.spearmanr(X, Y)\n",
    "                        label = \"%s: tau %d (%2.2f)\" % (network, tau, t_corr)\n",
    "\n",
    "                        im = ax.scatter(X, Y, c=C, marker=markers[network][0], **scatter_kwargs)\n",
    "                        ax.errorbar(X, Y, yerr=Y_err, xerr=X_err, fmt=markers[network], label=label, **error_kwargs)\n",
    "\n",
    "                    ax.set_xlabel(operation)\n",
    "\n",
    "                    handles, labels = ax.get_legend_handles_labels()\n",
    "                    ax.legend(handles, labels)\n",
    "\n",
    "                    ax.set_title(\"%s (%s)\" % (input_type, operation))\n",
    "            \n",
    "                xlims = [a*b for (a,b) in zip([.95, 1.05], [np.min(X), np.max(X)])]\n",
    "                ax.set_xlim(xlims) \n",
    "\n",
    "            m = cm.ScalarMappable(cmap=cm.jet)\n",
    "            m.set_array(2*temperatures[t0:])\n",
    "            fig.colorbar(m,  ax=axs.ravel().tolist(), orientation='horizontal', label='temperature',\n",
    "                        fraction=0.046) # , pad=0.04\n",
    "\n",
    "#             handles, labels = axs[0].get_legend_handles_labels()\n",
    "#             plt.figlegend( handles, labels, loc = 'upper center', ncol=5, labelspacing=0. )\n",
    "\n",
    "            plt.show() \n",
    "\n",
    "#                 fig_name = '%s/%s_%s_%s.png' % (fig_out_dir, fig_out_root, measure, input_type, network)\n",
    "#                 fig_files.append(fig_name)\n",
    "#                 savefig(fig_name)\n",
    "\n",
    "\n",
    "\n",
    "#     if len(fig_files):\n",
    "#         call([\"convert\"] + fig_files + ['-append', '%s/%s.png' % (fig_out_dir, fig_out_root)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "## Correlate difference between grid and random in the MI results vs differences in Pyphi results\n",
    "##########################################################################################################################\n",
    "\n",
    "fig_out_root = 'corr_phi_mi_diff_no_input'\n",
    "\n",
    "def sum_mi_over_mechanisms(all_measures):\n",
    "    \n",
    "    all_mi = all_measures[2]\n",
    "\n",
    "    ntemp = len(all_mi)\n",
    "    nruns = len(all_mi[0])\n",
    "    maxmec = len(all_mi[0][0][imn])+1\n",
    "\n",
    "#     Y_mean = [np.mean([np.sum(all_mi[t][r][imn]) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "#     Y_std = [np.std([np.sum(all_mi[t][r][imn]) for r in range(nruns)]) for t in range(ntemp)]  \n",
    "\n",
    "    Y_mean = [np.mean([np.sum(m/n for m,n in zip(all_mi[t][r][imn], range(1,maxmec))) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "    Y_std = [np.std([np.sum(m/n for m,n in zip(all_mi[t][r][imn], range(1,maxmec))) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "\n",
    "    return Y_mean, Y_std\n",
    "\n",
    "def log_sum_mi_over_mechanisms(all_measures):\n",
    "    Y_mean, Y_std = sum_mi_over_mechanisms(all_measures)\n",
    "    return np.log(Y_mean), Y_std\n",
    "\n",
    "def log_degeneracy(all_measures):\n",
    "    return np.log(np.abs(all_measures[0])), all_measures[1]\n",
    "\n",
    "def degeneracy(all_measures):\n",
    "    return all_measures[0], all_measures[1]\n",
    "\n",
    "# all_measures = [sum_mi_over_mechanisms, degeneracy]\n",
    "all_measures = [sum_mi_over_mechanisms, log_sum_mi_over_mechanisms, degeneracy, log_degeneracy]\n",
    "# all_measures = [sum_mi_over_mechanisms]\n",
    "\n",
    "all_phi = {'non': (all_results, all_results_std)}\n",
    "    \n",
    "for mi_input_file in mi_input_files:\n",
    "\n",
    "    measure_class = '_'.join(mi_input_file.split('_')[:3])\n",
    "\n",
    "    display(HTML(\"<center><h1 style='font-size: %dpx;height: 100;'>%s</h1></center>\" % (20, measure_class)))\n",
    "\n",
    "    with open('%s/%s' % (mi_input_dir, mi_input_file), 'rb') as f:\n",
    "        mis = pickle.load(f)\n",
    "\n",
    "    all_mi = {tau: {'Grid': {input_type: mis[tau][input_type + '_grid'] for input_type in input_types}, \n",
    "                    'Random': {input_type: mis[tau][input_type + '_rand'] for input_type in input_types}}\n",
    "                  for tau in mis}\n",
    "        \n",
    "    fig_files = []\n",
    "\n",
    "    for measure in all_measures:\n",
    "\n",
    "        # correlate \\Phi, \\sum \\phi and their product with MI-measures with \n",
    "        for input_type in input_types:\n",
    "\n",
    "            phi_for_input = all_phi[input_type]\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 2, sharey=True, figsize = (17,6))\n",
    "            axs[0].set_ylabel(measure.__name__)\n",
    "            axs_xlims = [[0, 0] for ax in axs]\n",
    "\n",
    "#                 cmap = matplotlib.cm.get_cmap('default', len(mis)).colors\n",
    "            for ax in axs: ax.set_prop_cycle(None)\n",
    "\n",
    "#                 for (iop, operation) in enumerate(sorted(phi_for_input[0][network])):\n",
    "            for (iop, operation) in enumerate(['big_phi', 'concepts']):\n",
    "\n",
    "                ax = axs[iop]\n",
    "\n",
    "                X = phi_for_input[0]['Grid'][operation][t0:] - phi_for_input[0]['Random'][operation][t0:]\n",
    "#                 X_err = np.sqrt(np.sum(phi_for_input[1]['Grid'][operation][t0:]**2 + phi_for_input[1]['Random'][operation][t0:]**2))\n",
    "                X_err = 0\n",
    "\n",
    "                if np.min(X) < axs_xlims[iop][0]: axs_xlims[iop][0] = np.min(X)\n",
    "                if np.max(X) > axs_xlims[iop][1]: axs_xlims[iop][1] = np.max(X)\n",
    "\n",
    "                for (itau, tau) in enumerate(mis):\n",
    "\n",
    "                    scatter_kwargs = {\"zorder\":100}\n",
    "#                         error_kwargs = {\"lw\":.5, \"zorder\":0, \"color\":cmap[itau, :]}\n",
    "                    error_kwargs = {\"lw\":.5, \"zorder\":0}\n",
    "\n",
    "                    Y_grid, Y_err_grid = measure(all_mi[tau]['Grid'][input_type])\n",
    "                    Y_random, Y_err_random = measure(all_mi[tau]['Random'][input_type])\n",
    "\n",
    "                    Y = [yg-yr for (yg,yr) in zip(Y_grid,Y_random)]\n",
    "                    Y_err = [np.sqrt(np.sum(yg**2 + yr**2)) for (yg,yr) in zip(Y_err_grid,Y_err_random)]\n",
    "\n",
    "                    Y, Y_err = Y[t0:], Y_err[t0:]\n",
    "                    \n",
    "#                     Y_err = 0\n",
    "\n",
    "                    C = cm.jet(np.linspace(0, 1, len(temperatures[t0:])))\n",
    "\n",
    "                    t_corr, p_corr = scipy.stats.pearsonr(X, Y)\n",
    "#                         t_corr, p_corr = scipy.stats.spearmanr(X, Y)\n",
    "                    label = \"tau %d (%2.2f)\" % (tau, t_corr)\n",
    "\n",
    "                    im = ax.scatter(X, Y, c=C, marker='s', **scatter_kwargs)\n",
    "                    ax.errorbar(X, Y, yerr=Y_err, xerr=X_err, fmt='s-', label=label, **error_kwargs)\n",
    "\n",
    "                ax.set_xlabel(operation)\n",
    "\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "                ax.legend(handles, labels)\n",
    "\n",
    "                ax.set_title(\"Grid-Random: %s (%s)\" % (input_type, operation))\n",
    "\n",
    "            xlims = [a*b for (a,b) in zip([.95, 1.05], [np.min(X), np.max(X)])]\n",
    "            ax.set_xlim(xlims) \n",
    "\n",
    "            m = cm.ScalarMappable(cmap=cm.jet)\n",
    "            m.set_array(2*temperatures[t0:])\n",
    "            fig.colorbar(m,  ax=axs.ravel().tolist(), orientation='horizontal', label='temperature',\n",
    "                        fraction=0.046) # , pad=0.04\n",
    "\n",
    "#             handles, labels = axs[0].get_legend_handles_labels()\n",
    "#             plt.figlegend( handles, labels, loc = 'upper center', ncol=5, labelspacing=0. )\n",
    "\n",
    "            plt.show() \n",
    "\n",
    "#                 fig_name = '%s/%s_%s_%s.png' % (fig_out_dir, fig_out_root, measure, input_type, network)\n",
    "#                 fig_files.append(fig_name)\n",
    "#                 savefig(fig_name)\n",
    "\n",
    "\n",
    "\n",
    "#     if len(fig_files):\n",
    "#         call([\"convert\"] + fig_files + ['-append', '%s/%s.png' % (fig_out_dir, fig_out_root)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "## Overlay all different MI measures regardless of \\Phi\n",
    "##########################################################################################################################\n",
    "\n",
    "import scipy \n",
    "\n",
    "fig_out_root = 'corr_phi_mi_diff_no_input'\n",
    "\n",
    "# t0 = 2\n",
    "t0 = 0\n",
    "\n",
    "mi_input_files = ['measure_d1_mice_grid_rand_non_test_T_0.0_2.8_new2.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_d1_mice_grid_non_N_9_2d_taus_0_1_5.pickle']\n",
    "trange = [0., 2.5]\n",
    "ntemp = 12\n",
    "temperatures = np.linspace(trange[0], trange[1], ntemp)\n",
    "\n",
    "# mi_input_files = ['measure_d1_v2_grid_rand_non_test_T_0.0_2.8.pickle',\n",
    "#                  'measure_dte_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_d1_mice_grid_rand_non_test_T_0.0_2.8_new.pickle',\n",
    "# 'measure_d1_cause_grid_rand_non_test_T_0.0_2.8_new.pickle',\n",
    "# 'measure_d1_effect_grid_rand_non_test_T_0.0_2.8_new.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_d1_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "# mi_input_files = ['measure_dte_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_d1_v2_grid_rand_non_test_T_0.0_2.8.pickle',\n",
    "#                  'measure_dte_v2_grid_rand_non_test_T_0.0_2.8.pickle']\n",
    "\n",
    "# mi_input_files = ['measure_dte_v2_grid_rand_non_test_T_0.5_1.0.pickle']\n",
    "\n",
    "markers = {'Grid': 'o-', 'Random': 'x--'}\n",
    "fcolor = {'Grid': m, 'Random': 'none'}\n",
    "\n",
    "use_average_mi = True\n",
    "# use_average_mi = False\n",
    "\n",
    "input_types = ['non']\n",
    "\n",
    "def sum_mi_over_mechanisms(all_measures):\n",
    "    \n",
    "    all_mi = all_measures[2]\n",
    "\n",
    "    ntemp = len(all_mi)\n",
    "    nruns = len(all_mi[0])\n",
    "    maxmec = len(all_mi[0][0][imn])+1\n",
    "\n",
    "    Y_mean = [np.mean([np.sum(all_mi[t][r][imn]) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "    Y_std = [np.std([np.sum(all_mi[t][r][imn]) for r in range(nruns)]) for t in range(ntemp)]  \n",
    "\n",
    "#     Y_mean = [np.mean([np.sum(m/n for m,n in zip(all_mi[t][r][imn], range(1,maxmec))) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "#     Y_std = [np.std([np.sum(m/n for m,n in zip(all_mi[t][r][imn], range(1,maxmec))) for r in range(nruns)]) for t in range(ntemp)]    \n",
    "\n",
    "    return Y_mean, Y_std\n",
    "\n",
    "def log_sum_mi_over_mechanisms(all_measures):\n",
    "    Y_mean, Y_std = sum_mi_over_mechanisms(all_measures)\n",
    "    return np.log(Y_mean), Y_std\n",
    "\n",
    "def log_degeneracy(all_measures):\n",
    "    return np.log(np.abs(all_measures[0])), all_measures[1]\n",
    "\n",
    "def degeneracy(all_measures):\n",
    "    return all_measures[0], all_measures[1]\n",
    "\n",
    "# all_measures = [sum_mi_over_mechanisms, degeneracy]\n",
    "all_measures = [sum_mi_over_mechanisms, log_sum_mi_over_mechanisms, degeneracy, log_degeneracy]\n",
    "# all_measures = [sum_mi_over_mechanisms]\n",
    "\n",
    "all_phi = {'non': (all_results, all_results_std)}\n",
    "    \n",
    "measure_markers = ['s-', 'o--', 'p:']\n",
    "all_mi_classes = dict()\n",
    "for (imi, mi_input_file) in enumerate(mi_input_files):\n",
    "\n",
    "    with open('%s/%s' % (mi_input_dir, mi_input_file), 'rb') as f:\n",
    "        mis = pickle.load(f)\n",
    "\n",
    "    measure_class = '_'.join(mi_input_file.split('_')[:3])\n",
    "\n",
    "    all_mi = {tau: {'Grid': {input_type: mis[tau][input_type + '_grid'] for input_type in input_types}}\n",
    "    \n",
    "#     all_mi = {tau: {'Grid': {input_type: mis[tau][input_type + '_grid'] for input_type in input_types}, \n",
    "#                     'Random': {input_type: mis[tau][input_type + '_rand'] for input_type in input_types}}\n",
    "                  for tau in mis}\n",
    "    \n",
    "    all_mi_classes[measure_class] = all_mi\n",
    "\n",
    "for measure in all_measures:\n",
    "\n",
    "    # correlate \\Phi, \\sum \\phi and their product with MI-measures with \n",
    "    for input_type in input_types:\n",
    "\n",
    "        fig = plt.figure(figsize = (17,6))\n",
    "        \n",
    "        for (imi, measure_class) in enumerate(all_mi_classes):\n",
    "            \n",
    "            plt.axes().set_prop_cycle(None)\n",
    "                \n",
    "            all_mi = all_mi_classes[measure_class]\n",
    "            \n",
    "            fig_files = []\n",
    "        \n",
    "#             ax = axs[imi]\n",
    "#             ax.set_xlabel(measure_class)\n",
    "\n",
    "            for (itau, tau) in enumerate(mis):\n",
    "\n",
    "                Y, Y_err = measure(all_mi[tau]['Grid'][input_type])\n",
    "                label = \"%s: tau %d\" % (measure_class, tau)\n",
    "                ax = plt.errorbar(temperatures[t0:], Y[t0:], yerr=Y_err[t0:], fmt=measure_markers[imi], label=label)\n",
    "\n",
    "        handles, labels = plt.axes().get_legend_handles_labels()\n",
    "        plt.legend(handles, labels)\n",
    "        plt.ylabel(measure.__name__)\n",
    "        plt.title(\"Different MIs for the Grid\")\n",
    "\n",
    "#         xlims = [a*b for (a,b) in zip([.95, 1.05], [np.min(X), np.max(X)])]\n",
    "#         ax.set_xlim(xlims) \n",
    "\n",
    "#         m = cm.ScalarMappable(cmap=cm.jet)\n",
    "#         m.set_array(2*temperatures[t0:])\n",
    "#         fig.colorbar(m,  ax=axs.ravel().tolist(), orientation='horizontal', label='temperature',\n",
    "#                     fraction=0.046) # , pad=0.04\n",
    "\n",
    "        plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
